# SKN17-FINAL-2Team

# 말하는대로 (AI 기반 회의 자동화 시스템)
음성에서 문서로. **실시간 녹음/업로드 → STT/화자 분리 → 도메인 기반 분석 → 안건/태스크 추출 → 캘린더 연동 → 웹 기반 회의록 생성**까지 **5단계 자동화**를 제공하는 회의 지원 솔루션입니다.

---

## 목차
- [프로젝트 개요](#프로젝트-개요)
- [핵심 기능](#핵심-기능)
- [시장 현황](#시장-현황)
- [시스템 아키텍처](#시스템-아키텍처)
- [데이터 파이프라인](#데이터-파이프라인)
  - [도메인 용어 처리 및 벡터DB](#도메인-용어-처리-및-벡터db)
  - [합성 데이터 생성 및 정제](#합성-데이터-생성-및-정제)
- [모델 선정 과정](#모델-선정-과정)
  - [STT 모델 선정](#stt-모델-선정)
  - [SLLM(회의 분석/추출) 모델 선정](#sllm회의-분석추출-모델-선정)
- [파인튜닝 및 평가](#파인튜닝-및-평가)
  - [평가 지표](#평가-지표)
  - [결과 요약](#결과-요약)
  - [베이스 모델 결과](#베이스-모델-결과)
- [시연 영상](#시연-영상)
- [팀 구성](#팀-구성)
- [비즈니스 모델(BM)](#비즈니스-모델bm)
- [기대 효과 & 발전 방향](#기대-효과--발전-방향)

---

## 프로젝트 개요
회의 후 녹음 파일을 재청취하며 회의록을 작성하는 과정은 **회의 시간의 추가 소모**, **핵심 결정 사항 누락**, **후속 조치(태스크) 추적 부재**로 이어질 수 있습니다.  
말하는대로는 회의 음성을 기반으로 **표준화된 문서 형식의 회의록**과 **안건/요약/태스크(담당자/마감)**를 구조화하여 제공합니다.

---

## 핵심 기능
| 구분 | 기능 | 설명 |
|---|---|---|
| 입력 | 실시간 녹음 / 파일 업로드 | 회의 중 녹음 또는 기존 음성 파일 업로드 |
| 음성 처리 | STT + 화자 분리 | 음성을 텍스트로 변환하고 발화자 구분 |
| 도메인 분석 | 도메인 용어 기반 컨텍스트 강화 | 사내/업무 용어를 인식하고 의미 보강(RAG) |
| 추출 | 안건/요약/태스크 자동 추출 | `누가/무엇을/언제까지`를 포함한 구조화 출력 |
| 연동 | 구글 캘린더 연동 | 추출된 태스크를 캘린더 일정으로 등록 |
| 출력 | 웹 기반 회의록 생성 | 표준 템플릿 문서로 회의록을 생성/조회 |


---

## 시장 현황
<이미지>

---

## 시스템 아키텍처
<이미지>

| 레이어 | 구성 요소 | 역할 |
|---|---|---|
| Web/App | Nginx, Django, Gunicorn, Docker, AWS EC2 | 사용자 요청 처리, 서비스 UI/인증/업무 로직 |
| Model Serving | FastAPI, RunPod | STT/화자분리/LLM 추론 API 제공 |
| STT & Diarization | OpenAI Whisper, pyannoteAI | 음성→텍스트, 화자 분리 |
| LLM | Qwen 계열 SLLM 파인튜닝 모델 | 안건/요약/태스크 구조화 추출 |
| RAG | FAISS Vector DB | 도메인 용어/정의 기반 컨텍스트 검색 |
| Storage/DB | AWS S3(WAV), AWS RDS(MySQL) | 파일 저장, 메타데이터/결과 저장 |
| External | Google Calendar | 태스크 일정 연동 |


---

## 데이터 파이프라인

### 도메인 용어 처리 및 벡터DB
- 도메인 용어 사전(Glossary)을 **메타데이터 기반 포맷**으로 정제 후 벡터DB에 저장합니다.
- 회의 내용에서 **전문 용어**를 찾아 관련 정의/설명을 검색하여 LLM 컨텍스트를 강화합니다.

### 합성 데이터 생성 및 정제
회의록/안건/태스크 추출을 안정적으로 학습시키기 위해, 회의 전문을 기반으로 **합성 데이터**를 생성하였습니다.

| 단계 | 내용 | 결과 |
|---|---|---|
| 생성 | “회의 전문 + (안건&태스크)” 형태로 생성 | 약 **2,600+ 케이스** 구축 |
| 스키마 검증 | JSON 스키마 기반 필드/형식 검증 | 총 **2621건 중 11건 오류 제거** |
| 중복 제거 | 유사 데이터 중복(pair) 제거 | **2621 → 2553**, 중복 0건 |
| 이상치 제거 | 발화자/시간 누락, 의미 유사도(BERT cosine) 기반 스코어링 | 평균 0.8809, **0.5 미만 49건 제거** |

---

## 모델 선정 과정

### STT 모델 선정
동일 음성(멘토링 음성, 11/13 샘플)에 대해 **CER(Character Error Rate)** 기반으로 비교하였으며, Whisper 계열이 상대적으로 우수했습니다.

| 후보 | CER | 비고 |
|---|---:|---|
| `openai/whisper-medium` | **0.1834** | **선정** |
| `openai/whisper-small` | 0.2522 |  |
| `openai/whisper-base` | 0.2874 |  |
| `kresnik/wav2vec2-large-xlsr-korean` | 0.8444 |  |
| `speechbrain/asr-conformer-transformer-ksponspeech` | 0.9864 |  |
| `facebook/seamless-m4t-v2-large` | 0.9538 |  |

화자 분리는 `pyannoteAI/speaker-diarization-3.1` 기반으로 구성하였습니다.

---

### SLLM(회의 분석/추출) 모델 선정
1) 한국어 LLM 리더보드(15B 이하)를 참고하여 후보를 도출하고  
2) 실제 “안건/태스크 추출” 태스크 성능(Precision/Recall/F1)을 비교하였습니다.

#### 1차 경량 모델 비교
| 모델 | Precision | Recall | F1 | 비고 |
|---|---:|---:|---:|---|
| `Qwen2.5-1.5B-Instruct` | **0.7560** | **0.7750** | **0.7653** | 1차 선정 |
| `Qwen2.5-7B-Instruct-1M` | 0.7481 | 0.7740 | 0.7607 |  |
| `skt/A.X-4.0-Light` | 0.7385 | 0.7623 | 0.7497 |  |
| `Qwen2.5-3B-Instruct` | 0.7323 | 0.7459 | 0.7387 |  |

> 모델이 작을수록 **출력 포맷 유지 실패/환각 증가/지시 준수 저하** 확인

#### 2차 비교 후보 확장
- `Qwen2.5-7B`는 `1.5B` 대비 출력 안정성이 개선되었으나 추론 시간이 오래 걸림
- 추가 비교 후보로 `Qwen3-8B`를 포함(지시 준수/장문 컨텍스트 성능 기대)

---

## 파인튜닝 및 평가

### 평가 지표
| 구분 | 지표 | 목적 |
|---|---|---|
| 자동 평가 | GPTScore (Faithfulness / Instruction-following / Structure-clarity) | 신뢰성, 지시 준수, 구조 명확성 |
| LLM 심사 | LLM-as-a-Judge (1~5점) | 정성 평가 기반 품질 비교 |
| 성능 | 응답 시간(초) | 실사용 관점 처리 시간 |

> GPTScore 평가 모델: `Qwen3-14B`  
> LLM Judge 모델: `gpt-4o-mini`

### 결과 요약
#### 파인튜닝 모델 간 비교
| 모델 | GPTScore(Faithfulness) | GPTScore(Instruction) | GPTScore(Structure) | Judge(Faith) | Judge(Inst) | Judge(Struct) | Time(s) |
|---|---:|---:|---:|---:|---:|---:|---:|
| Qwen2.5-1.5B (FT) | -0.695 | -0.707 | -0.738 | 1 | 1 | 5 | 36.07 |
| Qwen2.5-7B (FT) | -0.6172 | -0.637 | -0.683 | 3 | 4 | 5 | 125.55 |
| **Qwen3-8B (FT)** | **-0.432** | **-0.436** | **-0.453** | **5** | **4** | **5** | 166.94 |

#### 파인튜닝 vs 베이스라인
| 모델 | GPTScore(Faithfulness) | GPTScore(Instruction) | GPTScore(Structure) | Judge(Faith) | Judge(Inst) | Judge(Struct) | Time(s) |
|---|---:|---:|---:|---:|---:|---:|---:|
| **Qwen3-8B (FT)** | **-0.432** | **-0.436** | **-0.453** | **5** | **4** | **5** | 166.94 |
| Qwen3-8B (Base) | -2.453 | -2.625 | -2.734 | 1 | 1 | 1 | 249.809 |

### 베이스 모델 결과
베이스 모델은 다음과 같은 문제가 관찰되었습니다.
- **JSON 파싱 실패**(스키마 불일치)
- **안건/태스크 미생성**(빈 배열 반환)

반면 파인튜닝 모델은 **사전 정의된 출력 구조를 안정적으로 유지**하며 목표 기능(안건/태스크 추출)을 일관되게 수행하는 방향으로 개선되었습니다.

<이미지?>

---

## 시연 영상
영상?넣기

---

## 팀 구성
| 이름 | 역할 |
|---|---|
| 김수현 | 아이디어 제공 |
| 양송이 | 프로젝트 기획 및 문서 작업, 데이터 수집 및 전처리, 프론트엔드 & 백엔드 구현 |
| 이재은 | 프로젝트 기획 및 문서 작업, 데이터 수집 및 전처리, 프론트엔드 & 백엔드 구현 |
| 임길진 | 프론트엔드 & 백엔드 구현, 인프라 구성, SLLM 파인튜닝 |
| 전상아 | 프로젝트 기획 및 문서 작업, 모델 에이전트 구현, 벡터DB 구축, 데이터 수집 및 전처리 |
| 조해리 | 프로젝트 기획 및 문서 작업, 합성 데이터 생성 및 검증, 모델 테스트 자동화, SLLM 파인튜닝 |

---

## 비즈니스 모델(BM)
| 모델 | 개요 | 제공 가치 |
|---|---|---|
| SaaS 사업 모델 | 표준화된 회의 자동화 기능을 웹 기반으로 제공 | 빠른 온보딩, 낮은 도입 비용, 개인/팀 단위 장기 고객 확보 |
| Enterprise / B2B 솔루션 | 조직 맞춤형 회의 자동화 솔루션 제공 | 사내 도메인 용어 기반 커스터마이징, 보안 정책/권한 관리 |

---

## 기대 효과 & 발전 방향
### 기대 효과
- Enterprise API 사용에 대한 **보안 우려 해소**
- 보안 요구가 높은 기업 대상 **온프레미스 환경 지원**
- 회사/도메인별 특화 모델 제공으로 **회의 이해도 및 정확도 향상**

### 발전 방향
- 적용 도메인 확장(법무, 보험, 교육 등)
- STT 전문 전사 품질 보정 및 정확도 고도화
- 사용자 피드백 기반 지속 개선(Human-in-the-loop)

